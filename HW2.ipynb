{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "scikit-learn: 1.0.1\n",
      "mlxtend     : 0.19.0\n",
      "xgboost     : 1.5.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -p scikit-learn,mlxtend,xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://archive.ics.uci.edu/ml/datasets/Dry+Bean+Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (9119, 16)\n",
      "y_train.shape: (9119,)\n",
      "X_test.shape: (4492, 16)\n",
      "y_test.shape: (4492,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "X_train = pd.read_csv('https://raw.githubusercontent.com/rasbt/stat451-machine-learning-fs21/main/hw02-starter/dataset/X_train.csv', header=None).values\n",
    "y_train = pd.read_csv('https://raw.githubusercontent.com/rasbt/stat451-machine-learning-fs21/main/hw02-starter/dataset/y_train.csv', header=None).values.ravel().astype(int)\n",
    "\n",
    "X_test = pd.read_csv('https://raw.githubusercontent.com/rasbt/stat451-machine-learning-fs21/main/hw02-starter/dataset/X_test.csv', header=None).values\n",
    "y_test = pd.read_csv('https://raw.githubusercontent.com/rasbt/stat451-machine-learning-fs21/main/hw02-starter/dataset/y_test.csv', header=None).values.ravel().astype(int)\n",
    "\n",
    "print('X_train.shape:', X_train.shape)\n",
    "print('y_train.shape:', y_train.shape)\n",
    "print('X_test.shape:', X_test.shape)\n",
    "print('y_test.shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Valid/Test sizes: 9119 1824 4492\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train_sub, X_valid, y_train_sub, y_valid = \\\n",
    "    train_test_split(X_train, y_train, test_size=0.2, random_state=1, stratify=y_train)\n",
    "\n",
    "print('Train/Valid/Test sizes:', y_train.shape[0], y_valid.shape[0], y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare hyperparameter settings on validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 79.657%\n",
      "Valid Accuracy: 71.162%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_sub, y_train_sub)\n",
    "print(f\"Train Accuracy: {knn.score(X_train_sub, y_train_sub)*100:0.3f}%\")\n",
    "print(f\"Valid Accuracy: {knn.score(X_valid, y_valid)*100:0.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 84.003%\n",
      "Valid Accuracy: 71.930%\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train_sub, y_train_sub)\n",
    "print(f\"Train Accuracy: {knn.score(X_train_sub, y_train_sub)*100:0.3f}%\")\n",
    "print(f\"Valid Accuracy: {knn.score(X_valid, y_valid)*100:0.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 77.478%\n",
      "Valid Accuracy: 69.518%\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train_sub, y_train_sub)\n",
    "print(f\"Train Accuracy: {knn.score(X_train_sub, y_train_sub)*100:0.3f}%\")\n",
    "print(f\"Valid Accuracy: {knn.score(X_valid, y_valid)*100:0.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose best model and train on whole training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 84.965%\n",
      "Test Accuracy: 71.305%\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train, y_train)\n",
    "print(f\"Train Accuracy: {model.score(X_train, y_train)*100:0.3f}%\")\n",
    "print(f\"Test Accuracy: {model.score(X_test, y_test)*100:0.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3\n",
    "\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "import numpy as np\n",
    "import lightgbm\n",
    "import optuna\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "#optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "\n",
    "def objective(trial, X_train, y_train, cv=5):\n",
    "    \n",
    "    param_grid = {\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [10, 100]),\n",
    "        \"learning_rate\": trial.suggest_categorical(\"learning_rate\", [0.01]),\n",
    "    }\n",
    "    \n",
    "    cv_iterator = StratifiedKFold(n_splits=cv, shuffle=True, random_state=123)\n",
    "\n",
    "    cv_scores = np.zeros(cv)\n",
    "    for idx, (train_sub_idx, valid_idx) in enumerate(cv_iterator.split(X_train, y_train)):\n",
    "        \n",
    "        X_train_sub, X_valid = X_train[train_sub_idx], X_train[valid_idx]\n",
    "        y_train_sub, y_valid = y_train[train_sub_idx], y_train[valid_idx]\n",
    "\n",
    "        model = lightgbm.LGBMClassifier(objective=\"multi_logloss\", **param_grid)\n",
    "        model.fit(\n",
    "            X_train_sub,\n",
    "            y_train_sub,\n",
    "            eval_set=[(X_valid, y_valid)],\n",
    "            eval_metric=\"multi_logloss\",\n",
    "            verbose=-1,\n",
    "            early_stopping_rounds=50,\n",
    "            callbacks=[\n",
    "                LightGBMPruningCallback(trial=trial, metric=\"multi_logloss\")\n",
    "            ],  # Add a pruning callback to eliminate unpromising candidates\n",
    "        )\n",
    "        preds = model.score(X_valid, y_valid)\n",
    "        \n",
    "        cv_scores[idx] = preds\n",
    "\n",
    "    return 1-np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-16 14:36:37,102]\u001b[0m A new study created in memory with name: LGBM Classifier\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:36:39,875]\u001b[0m Trial 0 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:36:40,165]\u001b[0m Trial 1 finished with value: 0.48239960158212314 and parameters: {'n_estimators': 10, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:36:42,683]\u001b[0m Trial 2 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:36:42,979]\u001b[0m Trial 3 finished with value: 0.48239960158212314 and parameters: {'n_estimators': 10, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:36:43,285]\u001b[0m Trial 4 finished with value: 0.48239960158212314 and parameters: {'n_estimators': 10, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:36:43,615]\u001b[0m Trial 5 finished with value: 0.48239960158212314 and parameters: {'n_estimators': 10, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:36:46,374]\u001b[0m Trial 6 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:36:46,703]\u001b[0m Trial 7 finished with value: 0.48239960158212314 and parameters: {'n_estimators': 10, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:36:47,065]\u001b[0m Trial 8 finished with value: 0.48239960158212314 and parameters: {'n_estimators': 10, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:36:47,380]\u001b[0m Trial 9 finished with value: 0.48239960158212314 and parameters: {'n_estimators': 10, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:36:50,194]\u001b[0m Trial 10 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:36:53,339]\u001b[0m Trial 11 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:36:56,278]\u001b[0m Trial 12 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:36:59,535]\u001b[0m Trial 13 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:37:02,234]\u001b[0m Trial 14 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:37:04,863]\u001b[0m Trial 15 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:37:07,511]\u001b[0m Trial 16 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:37:10,148]\u001b[0m Trial 17 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:37:12,823]\u001b[0m Trial 18 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:37:15,449]\u001b[0m Trial 19 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:37:18,193]\u001b[0m Trial 20 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:37:20,846]\u001b[0m Trial 21 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:37:23,627]\u001b[0m Trial 22 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:37:26,419]\u001b[0m Trial 23 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:37:29,070]\u001b[0m Trial 24 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:37:31,768]\u001b[0m Trial 25 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:37:34,440]\u001b[0m Trial 26 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:37:37,096]\u001b[0m Trial 27 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:37:39,782]\u001b[0m Trial 28 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:37:42,472]\u001b[0m Trial 29 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:37:45,204]\u001b[0m Trial 30 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:37:48,220]\u001b[0m Trial 31 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:37:51,828]\u001b[0m Trial 32 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:37:55,914]\u001b[0m Trial 33 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:37:59,090]\u001b[0m Trial 34 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:37:59,422]\u001b[0m Trial 35 finished with value: 0.48239960158212314 and parameters: {'n_estimators': 10, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:38:02,220]\u001b[0m Trial 36 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:38:02,570]\u001b[0m Trial 37 finished with value: 0.48239960158212314 and parameters: {'n_estimators': 10, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:38:05,344]\u001b[0m Trial 38 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:38:05,727]\u001b[0m Trial 39 finished with value: 0.48239960158212314 and parameters: {'n_estimators': 10, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:38:08,715]\u001b[0m Trial 40 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-16 14:38:12,098]\u001b[0m Trial 41 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:38:15,413]\u001b[0m Trial 42 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:38:18,386]\u001b[0m Trial 43 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:38:21,276]\u001b[0m Trial 44 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:38:21,623]\u001b[0m Trial 45 finished with value: 0.48239960158212314 and parameters: {'n_estimators': 10, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:38:24,382]\u001b[0m Trial 46 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:38:27,091]\u001b[0m Trial 47 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:38:29,793]\u001b[0m Trial 48 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-16 14:38:32,484]\u001b[0m Trial 49 finished with value: 0.07511800964286763 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.07511800964286763.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\", study_name=\"LGBM Classifier\")\n",
    "\n",
    "def func(trial):\n",
    "    return objective(trial, X_train, y_train)\n",
    "\n",
    "study.optimize(func, n_trials=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBest value: 0.07512\n",
      "\tBest params:\n",
      "\t\tn_estimators: 100\n",
      "\t\tlearning_rate: 0.01\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\tBest value: {study.best_value:.5f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(learning_rate=0.01, objective='multi_logloss')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lightgbm.LGBMClassifier(objective=\"multi_logloss\", **study.best_params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 95.64645\n",
      "Valid Accuracy: 95.83333\n",
      "Test Accuracy: 92.16385\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Accuracy: {model.score(X_train, y_train)*100:0.5f}\")\n",
    "print(f\"Valid Accuracy: {model.score(X_valid, y_valid)*100:0.5f}\")\n",
    "print(f\"Test Accuracy: {model.score(X_test, y_test)*100:0.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.00\n",
      "Validation Accuracy: 1.00\n",
      "Test Accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "\n",
    "clf1 = KNeighborsClassifier(n_neighbors=5)\n",
    "clf2 = RandomForestClassifier(random_state=123)\n",
    "clf3 = HistGradientBoostingClassifier(random_state=123)\n",
    "clf4 = AdaBoostClassifier(random_state=123)\n",
    "clf5 = DecisionTreeClassifier(random_state=123,\n",
    "                              max_depth=None)\n",
    "\n",
    "lr = LogisticRegression(random_state=123)\n",
    "\n",
    "estimators = [('clf1', clf1),\n",
    "              ('clf2', clf2),\n",
    "              ('clf3', clf3),\n",
    "              ('clf4', clf4),\n",
    "              ('clf5', clf5)]\n",
    "\n",
    "sclf = StackingClassifier(estimators=estimators, \n",
    "                          final_estimator=lr, \n",
    "                          cv=10)\n",
    "\n",
    "\n",
    "sclf.fit(X_train, y_train)\n",
    "print(\"Training Accuracy: %0.2f\" % sclf.score(X_train, y_train))\n",
    "print(\"Validation Accuracy: %0.2f\" % sclf.score(X_valid, y_valid))\n",
    "print(\"Test Accuracy: %0.2f\" % sclf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.00000\n",
      "Validation Accuracy: 1.00000\n",
      "Test Accuracy: 0.92053\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Accuracy: %0.5f\" % sclf.score(X_train, y_train))\n",
    "print(\"Validation Accuracy: %0.5f\" % sclf.score(X_valid, y_valid))\n",
    "print(\"Test Accuracy: %0.5f\" % sclf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.00000\n",
      "Validation Accuracy: 1.00000\n",
      "Test Accuracy: 0.91986\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.classifier import StackingCVClassifier\n",
    "\n",
    "\n",
    "sclf = StackingCVClassifier(classifiers=[clf1, clf2, clf3, clf4, clf5], \n",
    "                            meta_classifier=lr, \n",
    "                            use_probas=True, # changed\n",
    "                            drop_proba_col='last',\n",
    "                            #use_features_in_secondary=True,\n",
    "                            cv=10,\n",
    "                            random_state=123)\n",
    "\n",
    "\n",
    "sclf.fit(X_train, y_train)\n",
    "print(\"Training Accuracy: %0.5f\" % sclf.score(X_train, y_train))\n",
    "print(\"Validation Accuracy: %0.5f\" % sclf.score(X_valid, y_valid))\n",
    "print(\"Test Accuracy: %0.5f\" % sclf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
