{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3 With Solutions (40 Pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAT 451: Machine Learning (Fall 2021)  \n",
    "Instructor: Sebastian Raschka (sraschka@wisc.edu)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Sebastian Raschka\n",
      "\n",
      "Last updated: 2023-01-24\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.7.6\n",
      "IPython version      : 7.12.0\n",
      "\n",
      "numpy     : 1.21.2\n",
      "scipy     : 1.7.1\n",
      "matplotlib: 3.4.3\n",
      "sklearn   : 1.0.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark  -d -u -a 'Sebastian Raschka' -v -p numpy,scipy,matplotlib,sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"paragraph\">\n",
    "  <p><br></p>\n",
    "  <p><br></p>\n",
    "  <p><br></p>\n",
    "  <p><br></p>\n",
    "  <p><br></p>\n",
    "  <p><br></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Hyperparameter Tuning and Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will be working with a diabetes dataset which is available from OpenML (https://www.openml.org/d/37).\n",
    "\n",
    "\n",
    "The dataset contains information about 768 patients along with the Diabetes diagnosis. The Diabetes diagnosis is a binary label, where \"tested_positive\" means that a patient has diabetes and \"tested_negative\" means that a patient does not have diabetes.\n",
    "\n",
    "I additional to the class label, there are 8 numeric features in the dataset, which are listed below:\n",
    "\n",
    "1. Number of times pregnant \n",
    "2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test \n",
    "3. Diastolic blood pressure (mm Hg) \n",
    "4. Triceps skin fold thickness (mm) \n",
    "5. 2-Hour serum insulin (mu U/ml) \n",
    "6. Body mass index (weight in kg/(height in m)^2) \n",
    "7. Diabetes pedigree function \n",
    "8. Age (years)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1  Using Grid Search for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1) Load the Dataset [5 Pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pandas to load the dataset from the `dataset_37_diabetes` file from OpenML. (Hint: I provided the correct link for that, but you need to change something in the `read_csv` default code to load it correctly.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insu</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     preg  plas  pres  skin  insu  mass   pedi  age            class\n",
       "763    10   101    76    48   180  32.9  0.171   63  tested_negative\n",
       "764     2   122    70    27     0  36.8  0.340   27  tested_negative\n",
       "765     5   121    72    23   112  26.2  0.245   30  tested_negative\n",
       "766     1   126    60     0     0  30.1  0.349   47  tested_positive\n",
       "767     1    93    70    31     0  30.4  0.315   23  tested_negative"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#------------------#\n",
    "##### STUDENTS #####\n",
    "#------------------#\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('https://www.openml.org/data/get_csv/37/dataset_37_diabetes.arff') # YOUR CODE\n",
    "#df.head()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2) Preprocess the class label [5 Pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the class label using pandas `apply` or `map` method. The mapping should be as follows:\n",
    "\n",
    "- `'tested_positive'` should be converted to `1`\n",
    "- `'tested_negative'` should be converted to `0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insu</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  insu  mass   pedi  age  class\n",
       "0     6   148    72    35     0  33.6  0.627   50      1\n",
       "1     1    85    66    29     0  26.6  0.351   31      0\n",
       "2     8   183    64     0     0  23.3  0.672   32      1\n",
       "3     1    89    66    23    94  28.1  0.167   21      0\n",
       "4     0   137    40    35   168  43.1  2.288   33      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#------------------#\n",
    "##### STUDENTS #####\n",
    "#------------------#\n",
    "\n",
    "df['class'] = df['class'].map({\"tested_positive\":1, \"tested_negative\":0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3) Split dataset into training and test sets [5 Pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split the dataset into 70% training and 30% test data\n",
    "- Perform a stratified split\n",
    "- use `0` as the random seed for shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------#\n",
    "##### STUDENTS #####\n",
    "#------------------#\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "y = df['class'].values\n",
    "X = df.iloc[:, :-1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4) Gridsearch and model selection [5 Pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, your task is to use `GridSearchCV` from scikit-learn to find the best parameters for `max_depth` and `criterion` for a decision tree. For max_depth, the values `[1, 2, 3, 4, 5, 10, 15, 20, None]` should be tried, and for criterion both Gini and Entropy should be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 75.04%\n"
     ]
    }
   ],
   "source": [
    "#------------------#\n",
    "##### STUDENTS #####\n",
    "#------------------#\n",
    "\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=123)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [1, 2, 3, 4, 5, 10, 15, 20, None],\n",
    "    'criterion': ['gini','entropy']\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(estimator=tree,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=10)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best Accuracy: %.2f%%' % (gs.best_score_*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, print the best hyperparameters obtained from the `GridSearchCV` run. Also, compute the accuracy the model, which uses the best hyperparameter settings and was trained on the whole training set, on the test set (`X_test`, `y_test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'criterion': 'entropy', 'max_depth': 4}\n",
      "Test Accuracy: 0.74%\n"
     ]
    }
   ],
   "source": [
    "#------------------#\n",
    "##### STUDENTS #####\n",
    "#------------------#\n",
    "\n",
    "\n",
    "print('Best Params: %s' % gs.best_params_)\n",
    "\n",
    "## model is already fit to the whole training set because  we used `refit=True` in GridSearchCV\n",
    "print('Test Accuracy: %.2f%%' % gs.best_estimator_.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you are asked to compute the accuracy of the model from the previous exercise (1.1), using the train set (`X_train`, `y_train`), via different bootstrap methods. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Compare the Out-of-Bag, .632, and .632+ bootstrap approaches [5 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For computing the bootstrap estimates and confidence intervals, you are going to use the `bootstrap_point632_score` function implemented in MLxtend: \n",
    "http://rasbt.github.io/mlxtend/user_guide/evaluate/bootstrap_point632_score/\n",
    "\n",
    "The accruacy should be the mean accuracy over the 200 bootstrap values that the `bootstrap_point632_score` method returns.\n",
    "\n",
    "- For this, use the best model you obtained from the previous exercise 1.1.4)\n",
    "- use 200 bootstrap rounds\n",
    "- set the random seed to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute Out-of-bag Bootstrap:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 67.44%\n",
      "95% Confidence interval: [0.61, 0.74]\n"
     ]
    }
   ],
   "source": [
    "#------------------#\n",
    "##### STUDENTS #####\n",
    "#------------------#\n",
    "\n",
    "from mlxtend.evaluate import bootstrap_point632_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Compute Out-of-bag Bootstrap\n",
    "scores = bootstrap_point632_score(gs,\n",
    "                                  X_train, y_train,\n",
    "                                  n_splits = 200,\n",
    "                                  method = 'oob',\n",
    "                                  random_seed = 1)\n",
    "\n",
    "\n",
    "# Compute accuracy (average over the bootstrap rounds)\n",
    "acc = np.mean(scores)\n",
    "print('Accuracy: %.2f%%' % (100*acc))\n",
    "\n",
    "# Compute the 95% confidence interval around the accuracy estimate\n",
    "lower = np.percentile(scores, 2.5)\n",
    "upper = np.percentile(scores, 97.5)\n",
    "print('95%% Confidence interval: [%.2f, %.2f]' % (lower, upper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**.632 Bootstrap:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.97%\n",
      "95% Confidence interval: [0.69, 0.80]\n"
     ]
    }
   ],
   "source": [
    "#------------------#\n",
    "##### STUDENTS #####\n",
    "#------------------#\n",
    "\n",
    "\n",
    "# Compute .632 Bootstrap\n",
    "scores = bootstrap_point632_score(gs,\n",
    "                                  X_train, y_train,\n",
    "                                  n_splits = 200,\n",
    "                                  random_seed = 1)\n",
    "\n",
    "\n",
    "# Compute accuracy (average over the bootstrap rounds)\n",
    "acc = np.mean(scores)\n",
    "print('Accuracy: %.2f%%' % (100*acc))\n",
    "\n",
    "# Compute the 95% confidence interval around the accuracy estimate\n",
    "lower = np.percentile(scores, 2.5)\n",
    "upper = np.percentile(scores, 97.5)\n",
    "print('95%% Confidence interval: [%.2f, %.2f]' % (lower, upper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute .632+ Bootstrap:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.07%\n",
      "95% Confidence interval: [0.63, 0.78]\n"
     ]
    }
   ],
   "source": [
    "#------------------#\n",
    "##### STUDENTS #####\n",
    "#------------------#\n",
    "\n",
    "\n",
    "# Compute .632+ Bootstrap\n",
    "scores = bootstrap_point632_score(gs,\n",
    "                                  X_train, y_train,\n",
    "                                  n_splits = 200,\n",
    "                                  method = '.632+',\n",
    "                                  random_seed = 1)\n",
    "\n",
    "\n",
    "# Compute accuracy (average over the bootstrap rounds)\n",
    "acc = np.mean(scores)\n",
    "print('Accuracy: %.2f%%' % (100*acc))\n",
    "\n",
    "# Compute the 95% confidence interval around the accuracy estimate\n",
    "lower = np.percentile(scores, 2.5)\n",
    "upper = np.percentile(scores, 97.5)\n",
    "print('95%% Confidence interval: [%.2f, %.2f]' % (lower, upper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.2 Analyzing the different bootstrap results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1) **[5 Pts]** Based on what you have learned it class, which of the three bootstrap methods (out-of-bag, 0.632, or 0.632+) do you expect to yield a generalization accuracy estimate from the training set that is closest to the true generalization performance of the model? Explain your reasoning in 1-3 sentences. (Tip: Think about optimistic and pessimistic bias).\n",
    "\n",
    "\n",
    "Out of bag would be the best because when we adjust for optimistic bias, the accuracy is around 77%. This is much closer to the training accuracy value of 75% from before. The other values after adjusting for optimistic bias aren't as close to 75%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2) **[5 Pts]** Based on your observations from the experiment in 1.2.1), which bootstrap approach (out-of-bag, 0.632, or 0.632+) yields an accuracy estimate from the training dataset that is closest to the test set accuracy from exercise 1.1.4? Is this reasonable? Explain your answer in 1-3 sentences. Also, to answer this question, assume that the test set accuracy from 1.1.4) is a perfect estimate of the true generalization accuracy of the model. \n",
    "\n",
    "It is 0.632 because the value of 74.97 is much closer to 75.04 than the 0.632+ value of 71.07. It is reasonable because we don't need to adjust for bias since we are given that it is a perfect estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3) **[5 Pts]** Based on your observations from the experiment in 1.2.1), are the overall results consistent with what you expected in your answer above (question 1))? Explain your reasoning in 3-5 sentences. Also, to answer this question, assume that the test set accuracy from 1.1.4) is a perfect estimate of the true generalization accuracy of the model. \n",
    "\n",
    "Tip: Discuss which methods are optimistically and pessimistically biased and whether this was expected.\n",
    "\n",
    "Yes, the accuracy is within the confidence intervals adjusting for bias. OOP can be optimistically bias, and adjusting for this brings us to close to the original model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
